## Task 22: Implement Real Logic for `BrowserAgentTool` - AI-driven `act` Action (Basic DOM Interaction)

**Focus:**
This task begins to implement the AI-driven `act` functionality in `BrowserAgentTool`. It will involve:
1.  Taking natural language instructions (e.g., "click the login button", "type 'testuser' into the username field").
2.  Using an LLM (e.g., OpenAI via a direct call or through a Pydantic AI agent sub-call if that pattern is preferred) to interpret these instructions and map them to simple Playwright actions on the current page (e.g., `click(selector)`, `fill(selector, text)`).
3.  For this initial version, we will focus on simple actions and selectors. We will *not* yet implement the full Stagehand capability of having the LLM *select* the element based on visual context or complex descriptions, but rather have it identify a plausible selector string for a given action type. More advanced element selection will be a follow-up.
4.  The `ActionExecutor` in `python/agents/browser_agent/actions.py` will house this logic.

**File Paths and Code Changes:**

1.  **Modify `python/agents/browser_agent/actions.py`:**
    *   Update `ActionExecutor.execute_ai_action` to make an LLM call to translate natural language instructions into basic Playwright commands (click, fill) and selectors.

    ```python
# python/agents/browser_agent/actions.py
    import asyncio
    from typing import Dict, Any, Optional, List
    from playwright.async_api import Page as PWPage, PlaywrightError
    import json

    # For LLM calls (similar to KnowledgeAgent or EmbeddingGenerator)
    import os
    from openai import OpenAI, APIError, RateLimitError
    from dotenv import load_dotenv
    from pathlib import Path

    project_root = Path(__file__).resolve().parents[2]
    dotenv_path = project_root / '.env'
    load_dotenv(dotenv_path, override=True)

    ACTION_TRANSLATION_SYSTEM_PROMPT = """
    You are an expert at translating natural language browser interaction commands into specific Playwright actions and CSS selectors.
    Given an instruction, identify the primary action (e.g., "click", "type", "fill", "navigate") and the target element.
    Respond with a JSON object containing:
    {
      "action_type": "click" | "fill" | "type" | "press" | "navigate" | "scroll" | "select_option",
      "selector": "CSS_SELECTOR_FOR_THE_TARGET_ELEMENT" (e.g., "button#login", "input[name='username']", "a[href='/about']"),
      "value": "TEXT_TO_TYPE_OR_FILL" (only for "fill" or "type" actions),
      "key": "KEY_TO_PRESS" (only for "press" action, e.g., "Enter", "ArrowDown"),
      "option_value": "VALUE_OF_OPTION_TO_SELECT" (only for "select_option" action)
      "scroll_direction": "down" | "up" | "bottom" | "top" (only for "scroll" action)
      "url": "URL_TO_NAVIGATE_TO" (only for "navigate" action)
    }
    Focus on common, simple selectors. If the target is ambiguous from the instruction alone, try to pick the most likely one.
    For "type", it means typing character by character. For "fill", it means setting the value at once.
    If the instruction is too complex or unclear for a single action, return an error or a request for clarification.
    Example Instruction: "Click the big blue login button"
    Example Response: {"action_type": "click", "selector": "button.primary[type='submit']"} (You might need to infer common class names or attributes)
    Example Instruction: "Type 'hello world' into the search bar"
    Example Response: {"action_type": "type", "selector": "input[type='search'], input[name='q'], input#search", "value": "hello world"} (Provide multiple likely selectors if not obvious)
    """

    class ActionExecutor:
        def __init__(self):
            self.api_key = os.getenv("OPENAI_API_KEY")
            self.llm_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini") # Use a capable chat model
            if not self.api_key:
                raise ValueError("OpenAI API key required for ActionExecutor.")
            self.llm_client = OpenAI(api_key=self.api_key)
            print(f"ActionExecutor: Initialized with OpenAI model '{self.llm_model}'.")

        async def _translate_instruction_to_action(self, page_context_summary: str, instruction: str) -> Optional[Dict[str, Any]]:
            """Uses LLM to translate natural language instruction to a structured action."""
            prompt = f"""
            Current Page Context Summary (e.g., title, visible interactive elements if available):
            ---
            {page_context_summary}
            ---
            User Instruction: "{instruction}"

            Translate this instruction into a specific browser action JSON.
            """
            messages = [
                {"role": "system", "content": ACTION_TRANSLATION_SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ]
            try:
                response = await asyncio.to_thread(
                    self.llm_client.chat.completions.create,
                    model=self.llm_model,
                    messages=messages,
                    response_format={"type": "json_object"}, # Request JSON output
                    temperature=0.1 # Low temperature for more deterministic output
                )
                action_json_str = response.choices[0].message.content
                action_dict = json.loads(action_json_str)
                print(f"ActionExecutor LLM translation: '{instruction}' -> {action_dict}")
                return action_dict
            except json.JSONDecodeError:
                print(f"ActionExecutor: LLM returned invalid JSON for instruction '{instruction}': {action_json_str}")
            except Exception as e:
                print(f"ActionExecutor: Error calling LLM for instruction translation: {e}")
            return None

        async def execute_ai_action(self, page: PWPage, instructions: str) -> Dict[str, Any]:
            print(f"ActionExecutor: Executing AI action on page {page.url} with instructions: '{instructions[:100]}...'")
            
            # Get a brief summary of the page for context (e.g., title, some element types)
            # This is a very simplified context summary. Stagehand would do more.
            page_title = await page.title()
            try:
                # Attempt to get some interactive elements to provide context to the LLM
                # This is very basic; a more robust approach would list elements with attributes
                buttons = await page.locator("button, input[type='submit'], a[role='button']").all_text_contents()
                inputs = await page.locator("input[type='text'], input[type='search'], input[type='email'], input[type='password'], textarea").all_inner_texts() # Using inner_text for inputs might be empty
                page_context_summary = f"Title: {page_title}. Visible buttons: {buttons[:3]}. Visible inputs: {len(inputs)}."
            except Exception:
                page_context_summary = f"Title: {page_title}. (Could not retrieve detailed elements)."


            parsed_action = await self._translate_instruction_to_action(page_context_summary, instructions)

            if not parsed_action or "action_type" not in parsed_action or "selector" not in parsed_action (
                and parsed_action["action_type"] not in ["navigate", "scroll"] # these might not need a selector
            ):
                return {"status": "error", "message": "Could not parse instruction into a valid action.", "original_instruction": instructions}

            action_type = parsed_action["action_type"]
            selector = parsed_action.get("selector") # Selector might be a comma-separated list
            value = parsed_action.get("value")
            key_to_press = parsed_action.get("key")
            option_value = parsed_action.get("option_value")
            scroll_direction = parsed_action.get("scroll_direction")
            url_to_navigate = parsed_action.get("url")

            action_details = {"type": action_type, "selector": selector, "value": value, "key": key_to_press, "url": url_to_navigate}
            
            try:
                # Handle multiple selectors by trying them in order
                final_selector_used = None
                target_locator = None

                if selector:
                    possible_selectors = [s.strip() for s in selector.split(',')]
                    for sel_option in possible_selectors:
                        try:
                            # Check if element is visible and enabled before interacting
                            # Use a short timeout for these checks.
                            locator = page.locator(sel_option)
                            await locator.wait_for(state="visible", timeout=2000)
                            if action_type in ["click", "fill", "type", "press", "select_option"]:
                                await locator.wait_for(state="enabled", timeout=2000)
                            target_locator = locator
                            final_selector_used = sel_option
                            print(f"ActionExecutor: Using selector '{final_selector_used}' for action '{action_type}'.")
                            break 
                        except PlaywrightError:
                            print(f"ActionExecutor: Selector option '{sel_option}' not found or not ready.")
                            continue # Try next selector
                    
                    if not target_locator and action_type not in ["navigate", "scroll", "press"]: # press might not need a selector if global
                        raise PlaywrightError(f"No suitable element found for selectors: {selector}")
                
                action_taken_message = ""

                if action_type == "click":
                    await target_locator.click(timeout=5000)
                    action_taken_message = f"Clicked element with selector: {final_selector_used}"
                elif action_type == "fill":
                    await target_locator.fill(value or "", timeout=5000)
                    action_taken_message = f"Filled element '{final_selector_used}' with value."
                elif action_type == "type":
                    await target_locator.type(value or "", delay=50, timeout=10000) # Add delay for typing
                    action_taken_message = f"Typed into element '{final_selector_used}'."
                elif action_type == "press":
                    if target_locator: # Press on a specific element
                        await target_locator.press(key_to_press, timeout=5000)
                        action_taken_message = f"Pressed key '{key_to_press}' on element '{final_selector_used}'."
                    else: # Global press
                        await page.keyboard.press(key_to_press)
                        action_taken_message = f"Pressed key '{key_to_press}' globally."
                elif action_type == "navigate":
                    if not url_to_navigate: raise ValueError("URL required for navigate action")
                    await page.goto(url_to_navigate, timeout=60000)
                    action_taken_message = f"Navigated to {url_to_navigate}"
                elif action_type == "scroll":
                    if scroll_direction == "down": await page.mouse.wheel(0, 500)
                    elif scroll_direction == "up": await page.mouse.wheel(0, -500)
                    elif scroll_direction == "bottom": await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                    elif scroll_direction == "top": await page.evaluate("window.scrollTo(0, 0)")
                    action_taken_message = f"Scrolled page {scroll_direction}"
                elif action_type == "select_option":
                    await target_locator.select_option(value=option_value) # or label=, or index=
                    action_taken_message = f"Selected option '{option_value}' in '{final_selector_used}'"
                else:
                    return {"status": "error", "message": f"Unsupported action_type: {action_type}", "parsed_action": parsed_action}

                await page.wait_for_load_state("domcontentloaded", timeout=5000) # Wait for potential page changes
                return {"status": "success", "action_taken": action_taken_message, "target_url": page.url, "final_selector": final_selector_used}

            except PlaywrightError as pe:
                print(f"ActionExecutor: PlaywrightError during '{action_type}' on '{final_selector_used or selector}': {str(pe)}")
                return {"status": "error", "message": f"Playwright interaction failed: {str(pe)}", "details": action_details}
            except Exception as e:
                print(f"ActionExecutor: Unexpected error during '{action_type}': {str(e)}")
                return {"status": "error", "message": f"Unexpected error: {str(e)}", "details": action_details}

        # ... (extract_data method remains largely placeholder, but now receives a real PWPage)
        async def extract_data(self, page: PWPage, instructions: str, schema: Optional[Dict] = None) -> Dict[str, Any]:
            print(f"ActionExecutor (Mock Extract): Extracting from page {page.url} with instructions: '{instructions[:100]}...'")
            # Placeholder for LLM call to extract data based on schema and page content
            # page.content() could be used to get HTML for the LLM
            page_title = await page.title()
            if schema:
                mock_data = {key: f"mock_value_for_{key}_from_{page_title}" for key in schema.get("properties", {}).keys()}
                return {"status": "success", "extracted_data": mock_data, "schema_used": True}
            else:
                return {"status": "success", "extracted_data": {"title": page_title, "first_heading": f"Mock Heading from {page_title}"}, "schema_used": False}
```

2.  **Modify `python/tools/browser_agent_tool.py`:**
    *   Ensure `_ai_act` calls the updated `ActionExecutor.execute_ai_action`. No major structural changes needed here if `ActionExecutor`'s interface is maintained.

**Dependencies/Prerequisites:**
*   Tasks 1-21 completed.
*   `playwright` library installed, browser binaries downloaded.
*   `openai` library installed, `OPENAI_API_KEY` and `OPENAI_MODEL` configured for the LLM calls within `ActionExecutor`.

**Integration with Agent Zero:**
*   `ActionExecutor` now makes a call to an LLM (OpenAI) to interpret natural language instructions into structured actions (action type, selector, value).
*   It then attempts to execute these simple actions (click, fill, type, press, navigate, scroll, select_option) on the Playwright `Page` object.
*   Error handling for Playwright actions is basic.
*   The `selector` parsing is very basic (tries comma-separated list). More advanced visual selection or LLM-based element identification is not yet implemented.

**Chatterbox TTS Integration Requirements for this Task:**
*   None directly.

**Docker Compatibility:**
*   Ensure `openai` is in `requirements.txt`.
*   The Docker container needs network access for OpenAI API calls.
*   `OPENAI_API_KEY` and `OPENAI_MODEL` environment variables must be available.

**Summary of Task 22:**
This task implements a foundational version of the AI-driven `act` action in the `BrowserAgentTool`. `ActionExecutor` now uses an LLM to parse natural language instructions into simple Playwright commands and attempts to execute them. This is a significant step towards enabling more natural language control over browser interactions, though it's still far from the full capabilities of Stagehand (which involves more sophisticated LLM reasoning for element selection and complex action sequences).

Please confirm to proceed.After completing Task 21, we've made substantial progress. The RAG pipeline (crawling -> chunking -> embedding -> storage -> retrieval -> generation) is structurally complete, with real fetching, embedding, Supabase storage, and LLM-based RAG response generation in place for the `KnowledgeAgentTool`. The `WebCrawlerTool` now feeds into this. `StreamProtocolTool` is handling basic event structures and WebSocket setup, and `MemoryAgentTool` and `ChatterboxTTSTool` have their real library integrations for core functions.

Let's reassess the remaining major areas based on our initial plan and the complexities revealed:

**Major Remaining Areas & Estimated Tasks:**

1.  **`BrowserAgentTool` (Stagehand) - Full AI Logic (High Complexity):**
    *   Task 22: Implement real AI-driven `act` (page interaction using LLMs like Stagehand does with `page.act()`). This involves taking natural language, converting it to Playwright actions (potentially via an LLM call), and executing them.
    *   Task 23: Implement real AI-driven `extract` (structured data extraction using LLMs and schemas like Stagehand's `page.extract()`).
    *   Task 24: Implement `agent_execute` (computer-use models). This is highly complex and might involve running a separate AI agent or a more sophisticated LLM interaction loop dedicated to browser tasks.
    *   Task 25: Robust error handling, state management (e.g., active page, context isolation) for Playwright within `BrowserManager` and `BrowserAgentTool`.

2.  **`MemoryAgentTool` (Mem0) - Advanced Features & Persistence (Medium-High Complexity):**
    *   Task 26: Integrate Mem0's graph memory capabilities (if applicable to its Python library version and our use case).
    *   Task 27: Integrate Mem0's LLM-based memory processing (summarization, entity/relationship extraction from stored memories).
    *   Task 28: Configure and implement persistence for Mem0 (e.g., to local files or a dedicated DB, if Mem0 supports it beyond in-memory).

3.  **`HybridMemoryTool` - Real Combination Logic (Medium Complexity):**
    *   Task 29: Implement the actual ranking, merging, and context selection algorithm in `_combine_memory_contexts` to effectively use results from both Agent Zero's native memory and `MemoryAgentTool`.

4.  **`ChatterboxTTSTool` - Voice Conversion & Advanced Features (Medium Complexity):**
    *   Task 30: Implement real logic for `convert_voice` in `ChatterboxVCHandler` using Chatterbox VC capabilities.
    *   Task 31: Refine audio output handling (e.g., options for streaming audio, more robust temporary file management, direct base64 for short clips, dedicated audio serving endpoint).

5.  **StreamProtocol & Agent Core - Finalizing Integration (Medium Complexity):**
    *   Task 32: Ensure all agent actions, tool calls, thoughts, and state changes consistently and correctly emit all 16 standard AG-UI events as appropriate. Refine payload structures for these events.
    *   Task 33: Finalize agent state management (`AgentContext.agent_state`) and its synchronization with client state via `STATE_DELTA` events.
    *   Task 34: Implement robust handling for `HUMAN_INTERVENTION` events if the frontend is expected to send them.

6.  **Configuration, Docker, and Final Touches (Medium Complexity):**
    *   Task 35: Comprehensive update of `settings.yaml` / `.env` for all new tools, models, API keys, and configurations.
    *   Task 36: Final Dockerfile review and optimization: ensure all dependencies (Python and system-level for Playwright, Torch, etc.) are correctly installed, model files are handled efficiently (baked in, downloaded to volumes, or via Hugging Face cache in a volume). Test multi-arch builds if planned.
    *   Task 37: Add comprehensive error handling, logging, and fault tolerance across all new components.
    *   Task 38: Write/update unit and integration tests for all new and modified tools and core functionalities.
    *   Task 39: Update Agent Zero's main README and any relevant documentation (`docs/` folder) to reflect all the "Phoenix" upgrades, new tools, and setup instructions.

**Rough Estimate of Remaining Tasks: 18 tasks (Tasks 22-39).**

This is an estimate, and some tasks might be broken down further or combined as we proceed. The complexity ratings give an idea of the effort involved.

Let's proceed with the next task.

## Task 22: Implement Real Logic for `BrowserAgentTool` - AI-driven `act` Action (Basic DOM Interaction)

**Focus:**
This task begins to implement the AI-driven `act` functionality in `BrowserAgentTool`. It will involve:
1.  Taking natural language instructions (e.g., "click the login button", "type 'testuser' into the username field").
2.  Using an LLM (e.g., OpenAI via a direct call or through a Pydantic AI agent sub-call if that pattern is preferred) to interpret these instructions and map them to simple Playwright actions on the current page (e.g., `click(selector)`, `fill(selector, text)`).
3.  For this initial version, we will focus on simple actions and selectors. We will *not* yet implement the full Stagehand capability of having the LLM *select* the element based on visual context or complex descriptions, but rather have it identify a plausible selector string for a given action type. More advanced element selection will be a follow-up.
4.  The `ActionExecutor` in `python/agents/browser_agent/actions.py` will house this logic.

**File Paths and Code Changes:**

1.  **Modify `python/agents/browser_agent/actions.py`:**
    *   Update `ActionExecutor.execute_ai_action` to make an LLM call to translate natural language instructions into basic Playwright commands (click, fill) and selectors.

    ```python
    # python/agents/browser_agent/actions.py
    import asyncio
    from typing import Dict, Any, Optional, List
    from playwright.async_api import Page as PWPage, PlaywrightError
    import json

    # For LLM calls (similar to KnowledgeAgent or EmbeddingGenerator)
    import os
    from openai import OpenAI, APIError, RateLimitError
    from dotenv import load_dotenv
    from pathlib import Path

    project_root = Path(__file__).resolve().parents[2]
    dotenv_path = project_root / '.env'
    load_dotenv(dotenv_path, override=True)

    ACTION_TRANSLATION_SYSTEM_PROMPT = """
    You are an expert at translating natural language browser interaction commands into specific Playwright actions and CSS selectors.
    Given an instruction, identify the primary action (e.g., "click", "type", "fill", "navigate") and the target element.
    Respond with a JSON object containing:
    {
      "action_type": "click" | "fill" | "type" | "press" | "navigate" | "scroll" | "select_option",
      "selector": "CSS_SELECTOR_FOR_THE_TARGET_ELEMENT" (e.g., "button#login", "input[name='username']", "a[href='/about']"),
      "value": "TEXT_TO_TYPE_OR_FILL" (only for "fill" or "type" actions),
      "key": "KEY_TO_PRESS" (only for "press" action, e.g., "Enter", "ArrowDown"),
      "option_value": "VALUE_OF_OPTION_TO_SELECT" (only for "select_option" action)
      "scroll_direction": "down" | "up" | "bottom" | "top" (only for "scroll" action)
      "url": "URL_TO_NAVIGATE_TO" (only for "navigate" action)
    }
    Focus on common, simple selectors. If the target is ambiguous from the instruction alone, try to pick the most likely one.
    For "type", it means typing character by character. For "fill", it means setting the value at once.
    If the instruction is too complex or unclear for a single action, return an error or a request for clarification.
    Example Instruction: "Click the big blue login button"
    Example Response: {"action_type": "click", "selector": "button.primary[type='submit']"} (You might need to infer common class names or attributes)
    Example Instruction: "Type 'hello world' into the search bar"
    Example Response: {"action_type": "type", "selector": "input[type='search'], input[name='q'], input#search", "value": "hello world"} (Provide multiple likely selectors if not obvious)
    """

    class ActionExecutor:
        def __init__(self):
            self.api_key = os.getenv("OPENAI_API_KEY")
            self.llm_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini") # Use a capable chat model
            if not self.api_key:
                raise ValueError("OpenAI API key required for ActionExecutor.")
            self.llm_client = OpenAI(api_key=self.api_key)
            print(f"ActionExecutor: Initialized with OpenAI model '{self.llm_model}'.")

        async def _translate_instruction_to_action(self, page_context_summary: str, instruction: str) -> Optional[Dict[str, Any]]:
            """Uses LLM to translate natural language instruction to a structured action."""
            prompt = f"""
            Current Page Context Summary (e.g., title, visible interactive elements if available):
            ---
            {page_context_summary}
            ---
            User Instruction: "{instruction}"

            Translate this instruction into a specific browser action JSON.
            """
            messages = [
                {"role": "system", "content": ACTION_TRANSLATION_SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ]
            try:
                response = await asyncio.to_thread(
                    self.llm_client.chat.completions.create,
                    model=self.llm_model,
                    messages=messages,
                    response_format={"type": "json_object"}, # Request JSON output
                    temperature=0.1 # Low temperature for more deterministic output
                )
                action_json_str = response.choices[0].message.content
                action_dict = json.loads(action_json_str)
                print(f"ActionExecutor LLM translation: '{instruction}' -> {action_dict}")
                return action_dict
            except json.JSONDecodeError:
                print(f"ActionExecutor: LLM returned invalid JSON for instruction '{instruction}': {action_json_str}")
            except Exception as e:
                print(f"ActionExecutor: Error calling LLM for instruction translation: {e}")
            return None

        async def execute_ai_action(self, page: PWPage, instructions: str) -> Dict[str, Any]:
            print(f"ActionExecutor: Executing AI action on page {page.url} with instructions: '{instructions[:100]}...'")
            
            # Get a brief summary of the page for context (e.g., title, some element types)
            # This is a very simplified context summary. Stagehand would do more.
            page_title = await page.title()
            try:
                # Attempt to get some interactive elements to provide context to the LLM
                # This is very basic; a more robust approach would list elements with attributes
                buttons = await page.locator("button, input[type='submit'], a[role='button']").all_text_contents()
                inputs = await page.locator("input[type='text'], input[type='search'], input[type='email'], input[type='password'], textarea").all_inner_texts() # Using inner_text for inputs might be empty
                page_context_summary = f"Title: {page_title}. Visible buttons: {buttons[:3]}. Visible inputs: {len(inputs)}."
            except Exception:
                page_context_summary = f"Title: {page_title}. (Could not retrieve detailed elements)."


            parsed_action = await self._translate_instruction_to_action(page_context_summary, instructions)

            if not parsed_action or "action_type" not in parsed_action or "selector" not in parsed_action (
                and parsed_action["action_type"] not in ["navigate", "scroll"] # these might not need a selector
            ):
                return {"status": "error", "message": "Could not parse instruction into a valid action.", "original_instruction": instructions}

            action_type = parsed_action["action_type"]
            selector = parsed_action.get("selector") # Selector might be a comma-separated list
            value = parsed_action.get("value")
            key_to_press = parsed_action.get("key")
            option_value = parsed_action.get("option_value")
            scroll_direction = parsed_action.get("scroll_direction")
            url_to_navigate = parsed_action.get("url")

            action_details = {"type": action_type, "selector": selector, "value": value, "key": key_to_press, "url": url_to_navigate}
            
            try:
                # Handle multiple selectors by trying them in order
                final_selector_used = None
                target_locator = None

                if selector:
                    possible_selectors = [s.strip() for s in selector.split(',')]
                    for sel_option in possible_selectors:
                        try:
                            # Check if element is visible and enabled before interacting
                            # Use a short timeout for these checks.
                            locator = page.locator(sel_option)
                            await locator.wait_for(state="visible", timeout=2000)
                            if action_type in ["click", "fill", "type", "press", "select_option"]:
                                await locator.wait_for(state="enabled", timeout=2000)
                            target_locator = locator
                            final_selector_used = sel_option
                            print(f"ActionExecutor: Using selector '{final_selector_used}' for action '{action_type}'.")
                            break 
                        except PlaywrightError:
                            print(f"ActionExecutor: Selector option '{sel_option}' not found or not ready.")
                            continue # Try next selector
                    
                    if not target_locator and action_type not in ["navigate", "scroll", "press"]: # press might not need a selector if global
                        raise PlaywrightError(f"No suitable element found for selectors: {selector}")
                
                action_taken_message = ""

                if action_type == "click":
                    await target_locator.click(timeout=5000)
                    action_taken_message = f"Clicked element with selector: {final_selector_used}"
                elif action_type == "fill":
                    await target_locator.fill(value or "", timeout=5000)
                    action_taken_message = f"Filled element '{final_selector_used}' with value."
                elif action_type == "type":
                    await target_locator.type(value or "", delay=50, timeout=10000) # Add delay for typing
                    action_taken_message = f"Typed into element '{final_selector_used}'."
                elif action_type == "press":
                    if target_locator: # Press on a specific element
                        await target_locator.press(key_to_press, timeout=5000)
                        action_taken_message = f"Pressed key '{key_to_press}' on element '{final_selector_used}'."
                    else: # Global press
                        await page.keyboard.press(key_to_press)
                        action_taken_message = f"Pressed key '{key_to_press}' globally."
                elif action_type == "navigate":
                    if not url_to_navigate: raise ValueError("URL required for navigate action")
                    await page.goto(url_to_navigate, timeout=60000)
                    action_taken_message = f"Navigated to {url_to_navigate}"
                elif action_type == "scroll":
                    if scroll_direction == "down": await page.mouse.wheel(0, 500)
                    elif scroll_direction == "up": await page.mouse.wheel(0, -500)
                    elif scroll_direction == "bottom": await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                    elif scroll_direction == "top": await page.evaluate("window.scrollTo(0, 0)")
                    action_taken_message = f"Scrolled page {scroll_direction}"
                elif action_type == "select_option":
                    await target_locator.select_option(value=option_value) # or label=, or index=
                    action_taken_message = f"Selected option '{option_value}' in '{final_selector_used}'"
                else:
                    return {"status": "error", "message": f"Unsupported action_type: {action_type}", "parsed_action": parsed_action}

                await page.wait_for_load_state("domcontentloaded", timeout=5000) # Wait for potential page changes
                return {"status": "success", "action_taken": action_taken_message, "target_url": page.url, "final_selector": final_selector_used}

            except PlaywrightError as pe:
                print(f"ActionExecutor: PlaywrightError during '{action_type}' on '{final_selector_used or selector}': {str(pe)}")
                return {"status": "error", "message": f"Playwright interaction failed: {str(pe)}", "details": action_details}
            except Exception as e:
                print(f"ActionExecutor: Unexpected error during '{action_type}': {str(e)}")
                return {"status": "error", "message": f"Unexpected error: {str(e)}", "details": action_details}

        # ... (extract_data method remains largely placeholder, but now receives a real PWPage)
        async def extract_data(self, page: PWPage, instructions: str, schema: Optional[Dict] = None) -> Dict[str, Any]:
            print(f"ActionExecutor (Mock Extract): Extracting from page {page.url} with instructions: '{instructions[:100]}...'")
            # Placeholder for LLM call to extract data based on schema and page content
            # page.content() could be used to get HTML for the LLM
            page_title = await page.title()
            if schema:
                mock_data = {key: f"mock_value_for_{key}_from_{page_title}" for key in schema.get("properties", {}).keys()}
                return {"status": "success", "extracted_data": mock_data, "schema_used": True}
            else:
                return {"status": "success", "extracted_data": {"title": page_title, "first_heading": f"Mock Heading from {page_title}"}, "schema_used": False}
    ```

2.  **Modify `python/tools/browser_agent_tool.py`:**
    *   Ensure `_ai_act` calls the updated `ActionExecutor.execute_ai_action`. No major structural changes needed here if `ActionExecutor`'s interface is maintained.

**Dependencies/Prerequisites:**
*   Tasks 1-21 completed.
*   `playwright` library installed, browser binaries downloaded.
*   `openai` library installed, `OPENAI_API_KEY` and `OPENAI_MODEL` configured for the LLM calls within `ActionExecutor`.

**Integration with Agent Zero:**
*   `ActionExecutor` now makes a call to an LLM (OpenAI) to interpret natural language instructions into structured actions (action type, selector, value).
*   It then attempts to execute these simple actions (click, fill, type, press, navigate, scroll, select_option) on the Playwright `Page` object.
*   Error handling for Playwright actions is basic.
*   The `selector` parsing is very basic (tries comma-separated list). More advanced visual selection or LLM-based element identification is not yet implemented.

**Chatterbox TTS Integration Requirements for this Task:**
*   None directly.

**Docker Compatibility:**
*   Ensure `openai` is in `requirements.txt`.
*   The Docker container needs network access for OpenAI API calls.
*   `OPENAI_API_KEY` and `OPENAI_MODEL` environment variables must be available.

**Summary of Task 22:**
This task implements a foundational version of the AI-driven `act` action in the `BrowserAgentTool`. `ActionExecutor` now uses an LLM to parse natural language instructions into simple Playwright commands and attempts to execute them. This is a significant step towards enabling more natural language control over browser interactions, though it's still far from the full capabilities of Stagehand (which involves more sophisticated LLM reasoning for element selection and complex action sequences).

Please confirm to proceed.